{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d48b75e5f9ac467fb484b5fbbfb3ec99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6897146855e44be8bc81e6a33a1cd0ac",
              "IPY_MODEL_1675c8f6af8c4af399d3f003f003da4d",
              "IPY_MODEL_fcd17e7956e148b6b89d59c1f6a66a1d"
            ],
            "layout": "IPY_MODEL_b1358c60f9ba423a9cac3b402553a9df"
          }
        },
        "6897146855e44be8bc81e6a33a1cd0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e39159c7dd3549f7af78077499db5c5f",
            "placeholder": "​",
            "style": "IPY_MODEL_f9c1c2c13e5f4869a8101acd556260d4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1675c8f6af8c4af399d3f003f003da4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ea5852f9c1a408ea015434416a878c2",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78a80a0d0912477c9dfa44a381a77453",
            "value": 49
          }
        },
        "fcd17e7956e148b6b89d59c1f6a66a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05c0e74292e6434fa6ef167d411afd04",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7fe6ca7d2340caa547c9c849488aec",
            "value": " 49.0/49.0 [00:00&lt;00:00, 2.52kB/s]"
          }
        },
        "b1358c60f9ba423a9cac3b402553a9df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e39159c7dd3549f7af78077499db5c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9c1c2c13e5f4869a8101acd556260d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ea5852f9c1a408ea015434416a878c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a80a0d0912477c9dfa44a381a77453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05c0e74292e6434fa6ef167d411afd04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7fe6ca7d2340caa547c9c849488aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5863b2275cfc43809f4e1f838732fa5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa3305df32ad4cd2a789e4bfbd12d820",
              "IPY_MODEL_cf7bc7b5e59d4b4198b4270ebe85f116",
              "IPY_MODEL_8c9ef5e2cebf4a0480396af47a8a98a7"
            ],
            "layout": "IPY_MODEL_dd646d2d559449a3a2179de3efc2b72d"
          }
        },
        "aa3305df32ad4cd2a789e4bfbd12d820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c3f6e3bb2c403a88c82f1d0601cb1a",
            "placeholder": "​",
            "style": "IPY_MODEL_292c8f72a076447abfcb5dd7efd560e8",
            "value": "config.json: 100%"
          }
        },
        "cf7bc7b5e59d4b4198b4270ebe85f116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7c30e2a438145d28baab275bbb71870",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba6f62dc05604a58a8784b16d7d9a632",
            "value": 625
          }
        },
        "8c9ef5e2cebf4a0480396af47a8a98a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cb3676bf72d4ab991f100222dc224f0",
            "placeholder": "​",
            "style": "IPY_MODEL_e0e8686ff5274ce4b03582d756d89e53",
            "value": " 625/625 [00:00&lt;00:00, 34.0kB/s]"
          }
        },
        "dd646d2d559449a3a2179de3efc2b72d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c3f6e3bb2c403a88c82f1d0601cb1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292c8f72a076447abfcb5dd7efd560e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7c30e2a438145d28baab275bbb71870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6f62dc05604a58a8784b16d7d9a632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cb3676bf72d4ab991f100222dc224f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e8686ff5274ce4b03582d756d89e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f93f7c50fe24281afc76f76d466e2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30573a7cb1b84ec6bf5f488bd502f01d",
              "IPY_MODEL_77f09aabcc944ed79998b55dd5da32ce",
              "IPY_MODEL_f3d6a86ab5e942378a70cdf09d430172"
            ],
            "layout": "IPY_MODEL_9d0f594d51da4310b9f3b0d2c52f8383"
          }
        },
        "30573a7cb1b84ec6bf5f488bd502f01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_760cc3950ac54062a6943fb1486f416b",
            "placeholder": "​",
            "style": "IPY_MODEL_c1709871d19a47be91b5425464fa6543",
            "value": "vocab.txt: 100%"
          }
        },
        "77f09aabcc944ed79998b55dd5da32ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f66997fd82274011a089788f88df0900",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97492f249edd40ea849635da654a3658",
            "value": 995526
          }
        },
        "f3d6a86ab5e942378a70cdf09d430172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e5df9ff751b4164840fea2bebe0c998",
            "placeholder": "​",
            "style": "IPY_MODEL_27d0422fd7be432081df08f29fde72e8",
            "value": " 996k/996k [00:00&lt;00:00, 45.9MB/s]"
          }
        },
        "9d0f594d51da4310b9f3b0d2c52f8383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "760cc3950ac54062a6943fb1486f416b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1709871d19a47be91b5425464fa6543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f66997fd82274011a089788f88df0900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97492f249edd40ea849635da654a3658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e5df9ff751b4164840fea2bebe0c998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d0422fd7be432081df08f29fde72e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99d6cb8beaab4a808eeeca6db936609e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_651c4578fcdd41b79d7b19134fd29deb",
              "IPY_MODEL_89f2f66575b645568bcf48236fc0d0bc",
              "IPY_MODEL_b807fc3514184c1db92ed85c1b335d6c"
            ],
            "layout": "IPY_MODEL_5547745ae17e490a900e1046abebf2f3"
          }
        },
        "651c4578fcdd41b79d7b19134fd29deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0cf94968b3744b48619be50db2137f3",
            "placeholder": "​",
            "style": "IPY_MODEL_fc5c93d108cd4693a60cf02bdef6ff97",
            "value": "tokenizer.json: 100%"
          }
        },
        "89f2f66575b645568bcf48236fc0d0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ebf64bfda0d41d08a168af0c670b799",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6cf10f984584723b68f250154e23805",
            "value": 1961828
          }
        },
        "b807fc3514184c1db92ed85c1b335d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d9cb9ce2f24c1faefa3984056f9e52",
            "placeholder": "​",
            "style": "IPY_MODEL_02088c0a9d074bd68af86338212beeae",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 8.87MB/s]"
          }
        },
        "5547745ae17e490a900e1046abebf2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0cf94968b3744b48619be50db2137f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc5c93d108cd4693a60cf02bdef6ff97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ebf64bfda0d41d08a168af0c670b799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6cf10f984584723b68f250154e23805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18d9cb9ce2f24c1faefa3984056f9e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02088c0a9d074bd68af86338212beeae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a78748376514d448c49ff33808e553c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bad34c8cf1d4a83b963a17d2bbdd58b",
              "IPY_MODEL_6f65352f03d04479ab7b4d16c93064e9",
              "IPY_MODEL_d2c7b52fe7f6446daf2bef3a001c70e2"
            ],
            "layout": "IPY_MODEL_658ac82b75414a75affd7f4a00fad0de"
          }
        },
        "9bad34c8cf1d4a83b963a17d2bbdd58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e2b5098de84ca69ba699bb02b8dcf5",
            "placeholder": "​",
            "style": "IPY_MODEL_8b4f6309b6d14703ae20fdd1c0289cc4",
            "value": "Map: 100%"
          }
        },
        "6f65352f03d04479ab7b4d16c93064e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c98e6bdcd84cdb9629ee3c3aa09b0d",
            "max": 2316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0d0a976eb2d4875b973c4811d74e8ca",
            "value": 2316
          }
        },
        "d2c7b52fe7f6446daf2bef3a001c70e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cc9dee27bce4dc4a8550ceda62f9b1b",
            "placeholder": "​",
            "style": "IPY_MODEL_c1fcb4bf916742b1a48cc653e509535f",
            "value": " 2316/2316 [00:00&lt;00:00, 6913.32 examples/s]"
          }
        },
        "658ac82b75414a75affd7f4a00fad0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e2b5098de84ca69ba699bb02b8dcf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b4f6309b6d14703ae20fdd1c0289cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c98e6bdcd84cdb9629ee3c3aa09b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d0a976eb2d4875b973c4811d74e8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cc9dee27bce4dc4a8550ceda62f9b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1fcb4bf916742b1a48cc653e509535f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78cc4267db57483293e59acdfb621c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fad9a282f1874148a5abc08a4e59dd7e",
              "IPY_MODEL_e6ecadad362f472394aee5333181d621",
              "IPY_MODEL_87400aba926049b4be9fe4b138e7063e"
            ],
            "layout": "IPY_MODEL_e9eb0c4fbae3431aabb43c8e47ec581b"
          }
        },
        "fad9a282f1874148a5abc08a4e59dd7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_912d692a186b41129cc36939e326dbd3",
            "placeholder": "​",
            "style": "IPY_MODEL_8e4f212d9f024fefba0bccfd124ca447",
            "value": "Map: 100%"
          }
        },
        "e6ecadad362f472394aee5333181d621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad3fdbc7893245d3916b6651864619b7",
            "max": 2316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e70df8ee35e419495e9880f5b332454",
            "value": 2316
          }
        },
        "87400aba926049b4be9fe4b138e7063e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfdf48f82bf2405287f1861ea1785dd9",
            "placeholder": "​",
            "style": "IPY_MODEL_0d3424e4803d4e21a0fc86a1296d9882",
            "value": " 2316/2316 [00:00&lt;00:00, 2787.01 examples/s]"
          }
        },
        "e9eb0c4fbae3431aabb43c8e47ec581b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "912d692a186b41129cc36939e326dbd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4f212d9f024fefba0bccfd124ca447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad3fdbc7893245d3916b6651864619b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e70df8ee35e419495e9880f5b332454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfdf48f82bf2405287f1861ea1785dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3424e4803d4e21a0fc86a1296d9882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning shared methods"
      ],
      "metadata": {
        "id": "Rouet0wOIDYZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3271536"
      },
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC # Import Support Vector Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier # Import Gradient Boosting and Random Forest Classifiers\n",
        "from sklearn.linear_model import LogisticRegression # Import Logistic Regression\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "\n",
        "def clean_text(text):\n",
        "    # URL Removal\n",
        "    # This pattern targets common URL formats (http(s)://, www., etc.)\n",
        "    url_pattern = r'https?://\\S+|www\\.\\S+|\\S+\\.(com|net|org|gov|edu|info|biz|co|me|io|ly|tv|pro|tel|aero|mobi|asia|int|mil|museum|name|jobs|travel|xyz|tk|cc|ws|fm|am|eu|us|ru|cn|jp|de|fr|uk|au|ca|it|es|nl|se|no|dk|fi|pl|cz|hu|ie|sg|hk|my|th|ph|vn|id|sa|ae|kw|qa|bh|om|eg|ma|dz|tn|sd|sy|iq|lb|jo|ye)\\b'\n",
        "    text = re.sub(url_pattern, ' ', text)\n",
        "    # Diacritics (Tashkeel) Removal\n",
        "    dia_pattren = r'[\\u064B-\\u0652\\u06D6-\\u06DC\\u06DF-\\u06E8\\u06EA-\\u06ED]'\n",
        "    text = re.sub(dia_pattren, ' ', text)\n",
        "    # Punctuation and Non-Arabic Characters Removal\n",
        "    text = re.sub(r'[^\\u0621-\\u064A\\u0660-\\u0669\\s]+', ' ', text)\n",
        "    # Repeats Reduction, as they can indecate emotions intensity\n",
        "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
        "    # Trim Extra Spaces\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "def vectorize_text(corpus, vectorizer=None, ngram_range=(1, 4)):\n",
        "    # Convert tokens into numeric features (TF-IDF, embeddings, etc.)\n",
        "    if vectorizer is None:\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
        "        vectorized_data = vectorizer.fit_transform(corpus)\n",
        "        return vectorizer, vectorized_data\n",
        "    else:\n",
        "        vectorized_data = vectorizer.transform(corpus)\n",
        "        return vectorized_data\n",
        "\n",
        "def train_model(X_train, y_train, model_type='naive_bayes'):\n",
        "    if model_type == 'naive_bayes':\n",
        "        model = MultinomialNB()\n",
        "    elif model_type == 'svm':\n",
        "        model = SVC()\n",
        "    elif model_type == 'gradient_boosting':\n",
        "        model = GradientBoostingClassifier(random_state=42)\n",
        "    elif model_type in ['logistic_regression','logistic']:\n",
        "        model = LogisticRegression(random_state=42, solver='liblinear') # Added Logistic Regression\n",
        "    elif model_type == 'decision_tree':\n",
        "        model = DecisionTreeClassifier(random_state=42) # Added Decision Tree Classifier\n",
        "    elif model_type == 'random_forest':\n",
        "        model = RandomForestClassifier(random_state=42) # Added Random Forest Classifier\n",
        "    else:\n",
        "        # Defaulting to a simple model or raising an error for unknown types\n",
        "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    # Evaluate performance metrics like accuracy and F1-score\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    return accuracy, report\n",
        "\n",
        "def predict_text(model, vectorizer, text):\n",
        "    # Run a single text prediction through the whole pipeline\n",
        "    cleaned = clean_text(text)\n",
        "    # Tokenization is now handled by CountVectorizer internally\n",
        "    vectorized = vectorizer.transform([cleaned])\n",
        "    return model.predict(vectorized)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset_path='sports_tweets.csv'\n",
        "df = pd.read_csv('sports_tweets.csv')\n",
        "df['cleaned_text'] = df['tweet'].apply(clean_text)\n",
        "model_types=['naive_bayes','svm','gradient_boosting','logistic_regression','decision_tree','random_forest']\n",
        "ngram_ranges=[(1,1),(1,2),(1,3),(1,4)]"
      ],
      "metadata": {
        "id": "__9xeKbrL4N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This is the parameters to setup"
      ],
      "metadata": {
        "id": "KasTfxLCL9KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ngram_range = (1, 1) # use (1,n) for ngram setup, currently using unigram(1-gram)\n",
        "model_type = 'naive_bayes'\n",
        "# Vectorize cleaned text with the specified n-gram range\n",
        "vectorizer, X_vectorized = vectorize_text(df['cleaned_text'], ngram_range=ngram_range)\n",
        "y = df['label']\n",
        "\n",
        "# Split data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "Uw4ZB88YrC9J",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This runs and trains the ML Models"
      ],
      "metadata": {
        "id": "YnE7YgYpJnO2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8313d46",
        "outputId": "60f1550c-8f10-4661-f286-a814bb8af735"
      },
      "source": [
        "\n",
        "#we will temporarily use the naive_bayes\n",
        "model = train_model(X_train, y_train, model_type=model_type)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "print(f\"Model Accuracy on {dataset_path} ({model_types[0]}) with {ngram_ranges[0]}-grams: {accuracy:.4f}\")\n",
        "print(f\"\\nClassification Report on {dataset_path} ({model_types[0]}) with {ngram_ranges[0]}-grams:\")\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy on sports_tweets.csv (naive_bayes) with (1, 1)-grams: 0.9526\n",
            "\n",
            "Classification Report on sports_tweets.csv (naive_bayes) with (1, 1)-grams:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.95      0.97      0.96       266\n",
            "         not       0.96      0.93      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.95      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce32b387",
        "outputId": "30ef3bba-3eb9-49ac-f78a-0a2aa2699c6c",
        "collapsed": true
      },
      "source": [
        "all_results=list()\n",
        "# Iterate through each model type\n",
        "for model_type in model_types:\n",
        "    # Iterate through each n-gram range\n",
        "    for ngram_range in ngram_ranges:\n",
        "        print(f\"\\n--- Evaluating Model: {model_type} with N-gram Range: {ngram_range} ---\")\n",
        "\n",
        "        # 2. Vectorize cleaned text with the current n-gram range\n",
        "        # A new vectorizer is created for each ngram_range to ensure correct feature generation\n",
        "        vectorizer, X_vectorized = vectorize_text(df['cleaned_text'], ngram_range=ngram_range)\n",
        "\n",
        "        # 3. Split data into training and testing sets (80-20 split)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # 4. Train the current model\n",
        "        model = train_model(X_train, y_train, model_type=model_type)\n",
        "\n",
        "        # 5. Evaluate the model\n",
        "        accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "        # Store the results\n",
        "        all_results.append({\n",
        "            'model_type': model_type,\n",
        "            'ngram_range': ngram_range,\n",
        "            'accuracy': accuracy,\n",
        "            'classification_report': report\n",
        "        })\n",
        "\n",
        "        print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(report)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Comprehensive Evaluation Results Summary\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Print summary of all results\n",
        "for result in all_results:\n",
        "    print(f\"\\nModel: {result['model_type']}, N-gram Range: {result['ngram_range']}\")\n",
        "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(result['classification_report'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Model: naive_bayes with N-gram Range: (1, 1) ---\n",
            "Model Accuracy: 0.9526\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.95      0.97      0.96       266\n",
            "         not       0.96      0.93      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.95      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: naive_bayes with N-gram Range: (1, 2) ---\n",
            "Model Accuracy: 0.9483\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.94      0.98      0.96       266\n",
            "         not       0.97      0.91      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.94      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: naive_bayes with N-gram Range: (1, 3) ---\n",
            "Model Accuracy: 0.9504\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.94      0.98      0.96       266\n",
            "         not       0.97      0.91      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.95      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: naive_bayes with N-gram Range: (1, 4) ---\n",
            "Model Accuracy: 0.9440\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.92      0.98      0.95       266\n",
            "         not       0.98      0.89      0.93       198\n",
            "\n",
            "    accuracy                           0.94       464\n",
            "   macro avg       0.95      0.94      0.94       464\n",
            "weighted avg       0.95      0.94      0.94       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: svm with N-gram Range: (1, 1) ---\n",
            "Model Accuracy: 0.9461\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.93      0.98      0.95       266\n",
            "         not       0.98      0.89      0.93       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.94      0.94       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: svm with N-gram Range: (1, 2) ---\n",
            "Model Accuracy: 0.9203\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.89      0.98      0.93       266\n",
            "         not       0.97      0.84      0.90       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.93      0.91      0.92       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: svm with N-gram Range: (1, 3) ---\n",
            "Model Accuracy: 0.9009\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.88      0.96      0.92       266\n",
            "         not       0.94      0.82      0.88       198\n",
            "\n",
            "    accuracy                           0.90       464\n",
            "   macro avg       0.91      0.89      0.90       464\n",
            "weighted avg       0.90      0.90      0.90       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: svm with N-gram Range: (1, 4) ---\n",
            "Model Accuracy: 0.8815\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.88      0.92      0.90       266\n",
            "         not       0.89      0.82      0.86       198\n",
            "\n",
            "    accuracy                           0.88       464\n",
            "   macro avg       0.88      0.87      0.88       464\n",
            "weighted avg       0.88      0.88      0.88       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: gradient_boosting with N-gram Range: (1, 1) ---\n",
            "Model Accuracy: 0.9073\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.86      1.00      0.92       266\n",
            "         not       0.99      0.79      0.88       198\n",
            "\n",
            "    accuracy                           0.91       464\n",
            "   macro avg       0.93      0.89      0.90       464\n",
            "weighted avg       0.92      0.91      0.91       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: gradient_boosting with N-gram Range: (1, 2) ---\n",
            "Model Accuracy: 0.9095\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.87      1.00      0.93       266\n",
            "         not       0.99      0.79      0.88       198\n",
            "\n",
            "    accuracy                           0.91       464\n",
            "   macro avg       0.93      0.89      0.90       464\n",
            "weighted avg       0.92      0.91      0.91       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: gradient_boosting with N-gram Range: (1, 3) ---\n",
            "Model Accuracy: 0.9030\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.86      1.00      0.92       266\n",
            "         not       0.99      0.78      0.87       198\n",
            "\n",
            "    accuracy                           0.90       464\n",
            "   macro avg       0.93      0.89      0.90       464\n",
            "weighted avg       0.92      0.90      0.90       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: gradient_boosting with N-gram Range: (1, 4) ---\n",
            "Model Accuracy: 0.9030\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.86      1.00      0.92       266\n",
            "         not       0.99      0.78      0.87       198\n",
            "\n",
            "    accuracy                           0.90       464\n",
            "   macro avg       0.93      0.89      0.90       464\n",
            "weighted avg       0.92      0.90      0.90       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: logistic_regression with N-gram Range: (1, 1) ---\n",
            "Model Accuracy: 0.9483\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.94      0.98      0.96       266\n",
            "         not       0.97      0.91      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.94      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: logistic_regression with N-gram Range: (1, 2) ---\n",
            "Model Accuracy: 0.9461\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.92      0.99      0.95       266\n",
            "         not       0.98      0.89      0.93       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.94      0.94       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: logistic_regression with N-gram Range: (1, 3) ---\n",
            "Model Accuracy: 0.9418\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.91      0.99      0.95       266\n",
            "         not       0.99      0.87      0.93       198\n",
            "\n",
            "    accuracy                           0.94       464\n",
            "   macro avg       0.95      0.93      0.94       464\n",
            "weighted avg       0.95      0.94      0.94       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: logistic_regression with N-gram Range: (1, 4) ---\n",
            "Model Accuracy: 0.9375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.91      0.99      0.95       266\n",
            "         not       0.99      0.86      0.92       198\n",
            "\n",
            "    accuracy                           0.94       464\n",
            "   macro avg       0.95      0.93      0.93       464\n",
            "weighted avg       0.94      0.94      0.94       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: decision_tree with N-gram Range: (1, 1) ---\n",
            "Model Accuracy: 0.8944\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.90      0.91      0.91       266\n",
            "         not       0.88      0.87      0.88       198\n",
            "\n",
            "    accuracy                           0.89       464\n",
            "   macro avg       0.89      0.89      0.89       464\n",
            "weighted avg       0.89      0.89      0.89       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: decision_tree with N-gram Range: (1, 2) ---\n",
            "Model Accuracy: 0.9116\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.92      0.93      0.92       266\n",
            "         not       0.90      0.89      0.90       198\n",
            "\n",
            "    accuracy                           0.91       464\n",
            "   macro avg       0.91      0.91      0.91       464\n",
            "weighted avg       0.91      0.91      0.91       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: decision_tree with N-gram Range: (1, 3) ---\n",
            "Model Accuracy: 0.9159\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.92      0.94      0.93       266\n",
            "         not       0.92      0.88      0.90       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.92      0.91      0.91       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: decision_tree with N-gram Range: (1, 4) ---\n",
            "Model Accuracy: 0.9203\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.93      0.94      0.93       266\n",
            "         not       0.91      0.90      0.91       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.92      0.92      0.92       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: random_forest with N-gram Range: (1, 1) ---\n",
            "Model Accuracy: 0.9310\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.91      0.98      0.94       266\n",
            "         not       0.97      0.87      0.91       198\n",
            "\n",
            "    accuracy                           0.93       464\n",
            "   macro avg       0.94      0.92      0.93       464\n",
            "weighted avg       0.93      0.93      0.93       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: random_forest with N-gram Range: (1, 2) ---\n",
            "Model Accuracy: 0.9181\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.88      0.99      0.93       266\n",
            "         not       0.98      0.82      0.90       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.93      0.91      0.91       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: random_forest with N-gram Range: (1, 3) ---\n",
            "Model Accuracy: 0.9203\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.88      0.99      0.93       266\n",
            "         not       0.99      0.82      0.90       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.94      0.91      0.92       464\n",
            "weighted avg       0.93      0.92      0.92       464\n",
            "\n",
            "\n",
            "--- Evaluating Model: random_forest with N-gram Range: (1, 4) ---\n",
            "Model Accuracy: 0.9095\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.87      0.98      0.93       266\n",
            "         not       0.98      0.81      0.88       198\n",
            "\n",
            "    accuracy                           0.91       464\n",
            "   macro avg       0.92      0.90      0.90       464\n",
            "weighted avg       0.92      0.91      0.91       464\n",
            "\n",
            "\n",
            "==================================================\n",
            "Comprehensive Evaluation Results Summary\n",
            "==================================================\n",
            "\n",
            "Model: naive_bayes, N-gram Range: (1, 1)\n",
            "Accuracy: 0.9526\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.95      0.97      0.96       266\n",
            "         not       0.96      0.93      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.95      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "Model: naive_bayes, N-gram Range: (1, 2)\n",
            "Accuracy: 0.9483\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.94      0.98      0.96       266\n",
            "         not       0.97      0.91      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.94      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "Model: naive_bayes, N-gram Range: (1, 3)\n",
            "Accuracy: 0.9504\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.94      0.98      0.96       266\n",
            "         not       0.97      0.91      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.95      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "Model: naive_bayes, N-gram Range: (1, 4)\n",
            "Accuracy: 0.9440\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.92      0.98      0.95       266\n",
            "         not       0.98      0.89      0.93       198\n",
            "\n",
            "    accuracy                           0.94       464\n",
            "   macro avg       0.95      0.94      0.94       464\n",
            "weighted avg       0.95      0.94      0.94       464\n",
            "\n",
            "\n",
            "Model: svm, N-gram Range: (1, 1)\n",
            "Accuracy: 0.9461\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.93      0.98      0.95       266\n",
            "         not       0.98      0.89      0.93       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.94      0.94       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "Model: svm, N-gram Range: (1, 2)\n",
            "Accuracy: 0.9203\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.89      0.98      0.93       266\n",
            "         not       0.97      0.84      0.90       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.93      0.91      0.92       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "Model: svm, N-gram Range: (1, 3)\n",
            "Accuracy: 0.9009\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.88      0.96      0.92       266\n",
            "         not       0.94      0.82      0.88       198\n",
            "\n",
            "    accuracy                           0.90       464\n",
            "   macro avg       0.91      0.89      0.90       464\n",
            "weighted avg       0.90      0.90      0.90       464\n",
            "\n",
            "\n",
            "Model: svm, N-gram Range: (1, 4)\n",
            "Accuracy: 0.8815\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.88      0.92      0.90       266\n",
            "         not       0.89      0.82      0.86       198\n",
            "\n",
            "    accuracy                           0.88       464\n",
            "   macro avg       0.88      0.87      0.88       464\n",
            "weighted avg       0.88      0.88      0.88       464\n",
            "\n",
            "\n",
            "Model: gradient_boosting, N-gram Range: (1, 1)\n",
            "Accuracy: 0.9073\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.86      1.00      0.92       266\n",
            "         not       0.99      0.79      0.88       198\n",
            "\n",
            "    accuracy                           0.91       464\n",
            "   macro avg       0.93      0.89      0.90       464\n",
            "weighted avg       0.92      0.91      0.91       464\n",
            "\n",
            "\n",
            "Model: gradient_boosting, N-gram Range: (1, 2)\n",
            "Accuracy: 0.9095\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.87      1.00      0.93       266\n",
            "         not       0.99      0.79      0.88       198\n",
            "\n",
            "    accuracy                           0.91       464\n",
            "   macro avg       0.93      0.89      0.90       464\n",
            "weighted avg       0.92      0.91      0.91       464\n",
            "\n",
            "\n",
            "Model: gradient_boosting, N-gram Range: (1, 3)\n",
            "Accuracy: 0.9030\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.86      1.00      0.92       266\n",
            "         not       0.99      0.78      0.87       198\n",
            "\n",
            "    accuracy                           0.90       464\n",
            "   macro avg       0.93      0.89      0.90       464\n",
            "weighted avg       0.92      0.90      0.90       464\n",
            "\n",
            "\n",
            "Model: gradient_boosting, N-gram Range: (1, 4)\n",
            "Accuracy: 0.9030\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.86      1.00      0.92       266\n",
            "         not       0.99      0.78      0.87       198\n",
            "\n",
            "    accuracy                           0.90       464\n",
            "   macro avg       0.93      0.89      0.90       464\n",
            "weighted avg       0.92      0.90      0.90       464\n",
            "\n",
            "\n",
            "Model: logistic_regression, N-gram Range: (1, 1)\n",
            "Accuracy: 0.9483\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.94      0.98      0.96       266\n",
            "         not       0.97      0.91      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.94      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "Model: logistic_regression, N-gram Range: (1, 2)\n",
            "Accuracy: 0.9461\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.92      0.99      0.95       266\n",
            "         not       0.98      0.89      0.93       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.94      0.94       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n",
            "\n",
            "Model: logistic_regression, N-gram Range: (1, 3)\n",
            "Accuracy: 0.9418\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.91      0.99      0.95       266\n",
            "         not       0.99      0.87      0.93       198\n",
            "\n",
            "    accuracy                           0.94       464\n",
            "   macro avg       0.95      0.93      0.94       464\n",
            "weighted avg       0.95      0.94      0.94       464\n",
            "\n",
            "\n",
            "Model: logistic_regression, N-gram Range: (1, 4)\n",
            "Accuracy: 0.9375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.91      0.99      0.95       266\n",
            "         not       0.99      0.86      0.92       198\n",
            "\n",
            "    accuracy                           0.94       464\n",
            "   macro avg       0.95      0.93      0.93       464\n",
            "weighted avg       0.94      0.94      0.94       464\n",
            "\n",
            "\n",
            "Model: decision_tree, N-gram Range: (1, 1)\n",
            "Accuracy: 0.8944\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.90      0.91      0.91       266\n",
            "         not       0.88      0.87      0.88       198\n",
            "\n",
            "    accuracy                           0.89       464\n",
            "   macro avg       0.89      0.89      0.89       464\n",
            "weighted avg       0.89      0.89      0.89       464\n",
            "\n",
            "\n",
            "Model: decision_tree, N-gram Range: (1, 2)\n",
            "Accuracy: 0.9116\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.92      0.93      0.92       266\n",
            "         not       0.90      0.89      0.90       198\n",
            "\n",
            "    accuracy                           0.91       464\n",
            "   macro avg       0.91      0.91      0.91       464\n",
            "weighted avg       0.91      0.91      0.91       464\n",
            "\n",
            "\n",
            "Model: decision_tree, N-gram Range: (1, 3)\n",
            "Accuracy: 0.9159\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.92      0.94      0.93       266\n",
            "         not       0.92      0.88      0.90       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.92      0.91      0.91       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "Model: decision_tree, N-gram Range: (1, 4)\n",
            "Accuracy: 0.9203\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.93      0.94      0.93       266\n",
            "         not       0.91      0.90      0.91       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.92      0.92      0.92       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "Model: random_forest, N-gram Range: (1, 1)\n",
            "Accuracy: 0.9310\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.91      0.98      0.94       266\n",
            "         not       0.97      0.87      0.91       198\n",
            "\n",
            "    accuracy                           0.93       464\n",
            "   macro avg       0.94      0.92      0.93       464\n",
            "weighted avg       0.93      0.93      0.93       464\n",
            "\n",
            "\n",
            "Model: random_forest, N-gram Range: (1, 2)\n",
            "Accuracy: 0.9181\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.88      0.99      0.93       266\n",
            "         not       0.98      0.82      0.90       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.93      0.91      0.91       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "Model: random_forest, N-gram Range: (1, 3)\n",
            "Accuracy: 0.9203\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.88      0.99      0.93       266\n",
            "         not       0.99      0.82      0.90       198\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.94      0.91      0.92       464\n",
            "weighted avg       0.93      0.92      0.92       464\n",
            "\n",
            "\n",
            "Model: random_forest, N-gram Range: (1, 4)\n",
            "Accuracy: 0.9095\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.87      0.98      0.93       266\n",
            "         not       0.98      0.81      0.88       198\n",
            "\n",
            "    accuracy                           0.91       464\n",
            "   macro avg       0.92      0.90      0.90       464\n",
            "weighted avg       0.92      0.91      0.91       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ef604e1",
        "outputId": "951e0b23-ddea-4657-b9ef-1283f8066690"
      },
      "source": [
        "best_accuracy = -1\n",
        "best_result = None\n",
        "\n",
        "for result in all_results:\n",
        "    if result['accuracy'] > best_accuracy:\n",
        "        best_accuracy = result['accuracy']\n",
        "        best_result = result\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Best Performing Model and N-gram Combination\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if best_result:\n",
        "    print(f\"Model Type: {best_result['model_type']}\")\n",
        "    print(f\"N-gram Range: {best_result['ngram_range']}\")\n",
        "    print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(best_result['classification_report'])\n",
        "else:\n",
        "    print(\"No results found to determine the best model.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Best Performing Model and N-gram Combination\n",
            "==================================================\n",
            "Model Type: naive_bayes\n",
            "N-gram Range: (1, 1)\n",
            "Accuracy: 0.9526\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.95      0.97      0.96       266\n",
            "         not       0.96      0.93      0.94       198\n",
            "\n",
            "    accuracy                           0.95       464\n",
            "   macro avg       0.95      0.95      0.95       464\n",
            "weighted avg       0.95      0.95      0.95       464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#- Here are the Deep Learning"
      ],
      "metadata": {
        "id": "H4ikzUqd9Aj_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eadc14a9"
      },
      "source": [
        "# Task\n",
        "Install `transformers`, `datasets`, and `accelerate` libraries, and import them in the current environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a16ed797"
      },
      "source": [
        "## Install and Import Libraries\n",
        "\n",
        "### Subtask:\n",
        "Install necessary Python libraries for Hugging Face Transformers, Datasets, and Accelerate, and import them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2abf85d"
      },
      "source": [
        "**Reasoning**:\n",
        "To complete the subtask, I need to install the specified libraries using pip and then import them in a Python code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e65f42a7",
        "outputId": "66062414-6d7a-4215-a417-9dfa2c1f6e8c"
      },
      "source": [
        "!pip install transformers datasets accelerate\n",
        "import transformers\n",
        "import datasets\n",
        "import accelerate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d3b9985"
      },
      "source": [
        "## Authenticate Hugging Face\n",
        "\n",
        "### Subtask:\n",
        "Authenticate to Hugging Face using the 'HF_TOKEN' Colab secret for model uploads and downloads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08129141"
      },
      "source": [
        "**Reasoning**:\n",
        "To authenticate to Hugging Face, I need to import the `notebook_login` function and then call it. This function is designed to handle authentication within Colab environments by leveraging Colab secrets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f034dd3"
      },
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "login(userdata.get('HF_TOKEN'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6e483c3"
      },
      "source": [
        "## Prepare Dataset for MBERT\n",
        "\n",
        "### Subtask:\n",
        "Tokenize the Arabic text data using the MBERT tokenizer and prepare it for model training. This will involve using the already cleaned text from the 'cleaned_text' column in the DataFrame and mapping the labels to integers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9850ab5c"
      },
      "source": [
        "**Reasoning**:\n",
        "I will start by importing the `AutoTokenizer` class from the `transformers` library and loading the `bert-base-multilingual-cased` tokenizer. Then, I'll define a function to tokenize the text, handling padding and truncation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "d48b75e5f9ac467fb484b5fbbfb3ec99",
            "6897146855e44be8bc81e6a33a1cd0ac",
            "1675c8f6af8c4af399d3f003f003da4d",
            "fcd17e7956e148b6b89d59c1f6a66a1d",
            "b1358c60f9ba423a9cac3b402553a9df",
            "e39159c7dd3549f7af78077499db5c5f",
            "f9c1c2c13e5f4869a8101acd556260d4",
            "8ea5852f9c1a408ea015434416a878c2",
            "78a80a0d0912477c9dfa44a381a77453",
            "05c0e74292e6434fa6ef167d411afd04",
            "6d7fe6ca7d2340caa547c9c849488aec",
            "5863b2275cfc43809f4e1f838732fa5a",
            "aa3305df32ad4cd2a789e4bfbd12d820",
            "cf7bc7b5e59d4b4198b4270ebe85f116",
            "8c9ef5e2cebf4a0480396af47a8a98a7",
            "dd646d2d559449a3a2179de3efc2b72d",
            "04c3f6e3bb2c403a88c82f1d0601cb1a",
            "292c8f72a076447abfcb5dd7efd560e8",
            "a7c30e2a438145d28baab275bbb71870",
            "ba6f62dc05604a58a8784b16d7d9a632",
            "8cb3676bf72d4ab991f100222dc224f0",
            "e0e8686ff5274ce4b03582d756d89e53",
            "4f93f7c50fe24281afc76f76d466e2c4",
            "30573a7cb1b84ec6bf5f488bd502f01d",
            "77f09aabcc944ed79998b55dd5da32ce",
            "f3d6a86ab5e942378a70cdf09d430172",
            "9d0f594d51da4310b9f3b0d2c52f8383",
            "760cc3950ac54062a6943fb1486f416b",
            "c1709871d19a47be91b5425464fa6543",
            "f66997fd82274011a089788f88df0900",
            "97492f249edd40ea849635da654a3658",
            "3e5df9ff751b4164840fea2bebe0c998",
            "27d0422fd7be432081df08f29fde72e8",
            "99d6cb8beaab4a808eeeca6db936609e",
            "651c4578fcdd41b79d7b19134fd29deb",
            "89f2f66575b645568bcf48236fc0d0bc",
            "b807fc3514184c1db92ed85c1b335d6c",
            "5547745ae17e490a900e1046abebf2f3",
            "e0cf94968b3744b48619be50db2137f3",
            "fc5c93d108cd4693a60cf02bdef6ff97",
            "8ebf64bfda0d41d08a168af0c670b799",
            "d6cf10f984584723b68f250154e23805",
            "18d9cb9ce2f24c1faefa3984056f9e52",
            "02088c0a9d074bd68af86338212beeae"
          ]
        },
        "id": "23026976",
        "outputId": "938e23f1-7b71-441c-cfb8-25d5be4aaea1"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the MBERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['cleaned_text'], truncation=True, padding='max_length', max_length=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d48b75e5f9ac467fb484b5fbbfb3ec99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5863b2275cfc43809f4e1f838732fa5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f93f7c50fe24281afc76f76d466e2c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99d6cb8beaab4a808eeeca6db936609e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "012ac20e"
      },
      "source": [
        "# Task\n",
        "Convert the pandas DataFrame to a Hugging Face Dataset, map the labels to integers, and then tokenize the dataset using the previously defined `tokenize_function`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7848ab1"
      },
      "source": [
        "## Prepare Dataset for MBERT\n",
        "\n",
        "### Subtask:\n",
        "Tokenize the Arabic text data using the MBERT tokenizer and prepare it for model training. This will involve using the already cleaned text from the 'cleaned_text' column in the DataFrame and mapping the labels to integers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58d24c36"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare the dataset for MBERT, I need to convert the pandas DataFrame to a Hugging Face Dataset, map string labels to integers, tokenize the text, and then format the dataset for PyTorch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174,
          "referenced_widgets": [
            "1a78748376514d448c49ff33808e553c",
            "9bad34c8cf1d4a83b963a17d2bbdd58b",
            "6f65352f03d04479ab7b4d16c93064e9",
            "d2c7b52fe7f6446daf2bef3a001c70e2",
            "658ac82b75414a75affd7f4a00fad0de",
            "91e2b5098de84ca69ba699bb02b8dcf5",
            "8b4f6309b6d14703ae20fdd1c0289cc4",
            "16c98e6bdcd84cdb9629ee3c3aa09b0d",
            "f0d0a976eb2d4875b973c4811d74e8ca",
            "3cc9dee27bce4dc4a8550ceda62f9b1b",
            "c1fcb4bf916742b1a48cc653e509535f",
            "78cc4267db57483293e59acdfb621c45",
            "fad9a282f1874148a5abc08a4e59dd7e",
            "e6ecadad362f472394aee5333181d621",
            "87400aba926049b4be9fe4b138e7063e",
            "e9eb0c4fbae3431aabb43c8e47ec581b",
            "912d692a186b41129cc36939e326dbd3",
            "8e4f212d9f024fefba0bccfd124ca447",
            "ad3fdbc7893245d3916b6651864619b7",
            "0e70df8ee35e419495e9880f5b332454",
            "bfdf48f82bf2405287f1861ea1785dd9",
            "0d3424e4803d4e21a0fc86a1296d9882"
          ]
        },
        "id": "f60ee4ae",
        "outputId": "6074a054-e349-4f36-8910-4f705f960de1"
      },
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# 1. Convert pandas DataFrame to Hugging Face Dataset\n",
        "hf_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# 2. Create a dictionary to map string labels to numerical integers\n",
        "label_mapping = {'hate': 0, 'not': 1}\n",
        "\n",
        "# 3. Apply this mapping to the 'label' column of the dataset\n",
        "hf_dataset = hf_dataset.map(lambda examples: {'labels': label_mapping[examples['label']]})\n",
        "\n",
        "# 4. Apply the tokenize_function to the dataset and remove unnecessary columns\n",
        "tokenized_dataset = hf_dataset.map(tokenize_function, batched=True, remove_columns=['tweet', 'cleaned_text', 'label', 'lemmatized_tweet'])\n",
        "\n",
        "# Set the format to 'torch'\n",
        "tokenized_dataset.set_format('torch')\n",
        "\n",
        "print(\"Dataset prepared successfully for MBERT training:\")\n",
        "print(tokenized_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2316 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a78748376514d448c49ff33808e553c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2316 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78cc4267db57483293e59acdfb621c45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared successfully for MBERT training:\n",
            "Dataset({\n",
            "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 2316\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1321ba64"
      },
      "source": [
        "## Split Data\n",
        "\n",
        "### Subtask:\n",
        "Split the prepared dataset into training and testing sets for fine-tuning and evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a28794a"
      },
      "source": [
        "**Reasoning**:\n",
        "To split the dataset into training and testing sets, I will use the `train_test_split` method on the `tokenized_dataset` with the specified `test_size` and `seed`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "952dddc4",
        "outputId": "2d6bf044-2854-4732-c42b-f8297b177714"
      },
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# Split the tokenized dataset into training and testing sets\n",
        "train_test_split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "train_dataset = train_test_split_dataset['train']\n",
        "test_dataset = train_test_split_dataset['test']\n",
        "\n",
        "print(\"Dataset split successfully:\")\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Testing dataset size: {len(test_dataset)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split successfully:\n",
            "Training dataset size: 1852\n",
            "Testing dataset size: 464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cada54f"
      },
      "source": [
        "## Load MBERT Model and Define Training Arguments\n",
        "\n",
        "### Subtask:\n",
        "Load a pre-trained `bert-base-multilingual-cased` model for sequence classification and configure training arguments, including hyperparameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b1111df"
      },
      "source": [
        "**Reasoning**:\n",
        "To achieve the subtask, I need to import `AutoModelForSequenceClassification`, `TrainingArguments`, and `Trainer` from the transformers library. Then, I will load the MBERT model for sequence classification and define the training arguments as specified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88892859",
        "outputId": "642fe06a-258b-4180-8571-2263f528258c"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# 1. Load the pre-trained MBERT model for sequence classification\n",
        "#    Set num_labels to 2 for binary classification (hate/not hate)\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "\n",
        "# 2. Configure TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory for model predictions and checkpoints\n",
        "    learning_rate=2e-5,              # The initial learning rate for AdamW optimizer\n",
        "    per_device_train_batch_size=16,  # Batch size per GPU/TPU core/CPU for training\n",
        "    per_device_eval_batch_size=16,   # Batch size per GPU/TPU core/CPU for evaluation\n",
        "    num_train_epochs=3,              # Total number of training epochs to perform\n",
        "    weight_decay=0.01,               # Strength of weight decay\n",
        "    eval_strategy=\"epoch\",     # Evaluation is done at the end of each epoch\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=10,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4135fe47"
      },
      "source": [
        "**Reasoning**:\n",
        "To properly evaluate the model during training, I need to define a `compute_metrics` function. This function will take predictions and labels as input and return a dictionary of evaluation metrics, such as accuracy and F1-score, which are essential for tracking model performance. I will import `accuracy_score` and `f1_score` from `sklearn.metrics` for this purpose.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67b475c3"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='weighted') # Using weighted average for F1-score\n",
        "    return {'accuracy': accuracy, 'f1_score': f1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25a7f481"
      },
      "source": [
        "**Reasoning**:\n",
        "I have already defined the `compute_metrics` function in the previous step as requested. Now I need to integrate this function into the `Trainer` setup to use it during model training and evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e749beae",
        "outputId": "983ebf3c-cb12-46d5-9c6b-d093033d4e8b"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# 1. Load the pre-trained MBERT model for sequence classification\n",
        "#    Set num_labels to 2 for binary classification (hate/not hate)\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "\n",
        "# 2. Configure TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory for model predictions and checkpoints\n",
        "    learning_rate=2e-5,              # The initial learning rate for AdamW optimizer\n",
        "    per_device_train_batch_size=16,  # Batch size per GPU/TPU core/CPU for training\n",
        "    per_device_eval_batch_size=16,   # Batch size per GPU/TPU core/CPU for evaluation\n",
        "    num_train_epochs=3,              # Total number of training epochs to perform\n",
        "    weight_decay=0.01,               # Strength of weight decay\n",
        "    eval_strategy=\"epoch\",     # Evaluation is done at the end of each epoch\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# 3. Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-4251758536.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a138319"
      },
      "source": [
        "**Reasoning**:\n",
        "The `Trainer` has been successfully initialized, despite a `FutureWarning`. The next logical step in the machine learning pipeline is to train the model using the configured `Trainer` instance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "6a1780f0",
        "outputId": "b0e05d28-9cc0-424a-f413-943ec13308c6"
      },
      "source": [
        "trainer.train()\n",
        "print(\"Model training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33me33u33\u001b[0m (\u001b[33me33u33-king-saud-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251117_131112-bau29j3p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/e33u33-king-saud-university/huggingface/runs/bau29j3p' target=\"_blank\">serene-music-1</a></strong> to <a href='https://wandb.ai/e33u33-king-saud-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/e33u33-king-saud-university/huggingface' target=\"_blank\">https://wandb.ai/e33u33-king-saud-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/e33u33-king-saud-university/huggingface/runs/bau29j3p' target=\"_blank\">https://wandb.ai/e33u33-king-saud-university/huggingface/runs/bau29j3p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [348/348 2:06:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.313800</td>\n",
              "      <td>0.487658</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.744126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.166600</td>\n",
              "      <td>0.262635</td>\n",
              "      <td>0.918103</td>\n",
              "      <td>0.917924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.103000</td>\n",
              "      <td>0.288629</td>\n",
              "      <td>0.915948</td>\n",
              "      <td>0.916037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d29fb9bf"
      },
      "source": [
        "**Reasoning**:\n",
        "The model has been trained successfully. Now, I need to evaluate its performance on the test dataset using the `trainer.evaluate()` method to get the final metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "768850c1",
        "outputId": "a5975196-d69f-4503-8499-a8612310dbcb"
      },
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(\"Model evaluation complete:\")\n",
        "print(eval_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [29/29 02:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model evaluation complete:\n",
            "{'eval_loss': 0.2886291444301605, 'eval_accuracy': 0.915948275862069, 'eval_f1_score': 0.916036950074367, 'eval_runtime': 182.0152, 'eval_samples_per_second': 2.549, 'eval_steps_per_second': 0.159, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190fa32d"
      },
      "source": [
        "**Reasoning**:\n",
        "The model has been evaluated, and the `eval_results` dictionary contains the final performance metrics. I will extract and present the key metrics from this dictionary to summarize the deep learning model's performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "0963edb6",
        "outputId": "6e2c81c7-760c-4523-f53f-cd22352aa2c6"
      },
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(\"Model evaluation complete:\")\n",
        "print(eval_results)\n",
        "\n",
        "# Extract and print key metrics for clarity\n",
        "print(f\"\\nDeep Learning Model (MBERT) Performance:\")\n",
        "print(f\"  Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
        "print(f\"  F1-score (weighted): {eval_results['eval_f1_score']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='58' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [29/29 06:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model evaluation complete:\n",
            "{'eval_loss': 0.2886291444301605, 'eval_accuracy': 0.915948275862069, 'eval_f1_score': 0.916036950074367, 'eval_runtime': 176.4626, 'eval_samples_per_second': 2.629, 'eval_steps_per_second': 0.164, 'epoch': 3.0}\n",
            "\n",
            "Deep Learning Model (MBERT) Performance:\n",
            "  Accuracy: 0.9159\n",
            "  F1-score (weighted): 0.9160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "521540e6"
      },
      "source": [
        "**Reasoning**:\n",
        "The user wants to store the deep learning model's performance metrics in a variable for later use. I will extract the accuracy and F1-score from the `eval_results` and assign them to a new dictionary named `dl_results`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "22476c53",
        "outputId": "094b49ba-f3b4-4384-91e6-87febe52af8f"
      },
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(\"Model evaluation complete:\")\n",
        "print(eval_results)\n",
        "\n",
        "# Extract and print key metrics for clarity\n",
        "print(f\"\\nDeep Learning Model (MBERT) Performance:\")\n",
        "print(f\"  Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
        "print(f\"  F1-score (weighted): {eval_results['eval_f1_score']:.4f}\")\n",
        "\n",
        "dl_results = {\n",
        "    'model_type': 'MBERT',\n",
        "    'accuracy': eval_results['eval_accuracy'],\n",
        "    'f1_score': eval_results['eval_f1_score']\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='87' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [29/29 09:14]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model evaluation complete:\n",
            "{'eval_loss': 0.2886291444301605, 'eval_accuracy': 0.915948275862069, 'eval_f1_score': 0.916036950074367, 'eval_runtime': 177.1797, 'eval_samples_per_second': 2.619, 'eval_steps_per_second': 0.164, 'epoch': 3.0}\n",
            "\n",
            "Deep Learning Model (MBERT) Performance:\n",
            "  Accuracy: 0.9159\n",
            "  F1-score (weighted): 0.9160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dad90c4d"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to compare the deep learning model's performance with the best classical ML model. I will display the results of both and then determine and print which one achieved higher accuracy and F1-score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1956cc10",
        "outputId": "0b3c360d-a48d-4003-c9e5-6e32df9e1f15"
      },
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Model Performance Comparison (Classical ML vs. Deep Learning)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Display best Classical ML model results\n",
        "if best_result:\n",
        "    print(f\"\\nBest Classical ML Model ({best_result['model_type']} with {best_result['ngram_range']}-grams):\")\n",
        "    print(f\"  Accuracy: {best_result['accuracy']:.4f}\")\n",
        "    print(f\"  F1-score: {float(best_result['classification_report'].split()[-2]):.4f}\") # Extract F1-score from report\n",
        "else:\n",
        "    print(\"No classical ML results found.\")\n",
        "\n",
        "# Display Deep Learning model results\n",
        "if dl_results:\n",
        "    print(f\"\\nDeep Learning Model ({dl_results['model_type']}):\")\n",
        "    print(f\"  Accuracy: {dl_results['accuracy']:.4f}\")\n",
        "    print(f\"  F1-score: {dl_results['f1_score']:.4f}\")\n",
        "else:\n",
        "    print(\"No deep learning results found.\")\n",
        "\n",
        "# Compare and determine the best overall model\n",
        "if best_result and dl_results:\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    if dl_results['accuracy'] > best_result['accuracy']:\n",
        "        print(\"The Deep Learning model performed better in Accuracy.\")\n",
        "    elif best_result['accuracy'] > dl_results['accuracy']:\n",
        "        print(\"The Best Classical ML model performed better in Accuracy.\")\n",
        "    else:\n",
        "        print(\"Both models achieved similar accuracy.\")\n",
        "\n",
        "    if dl_results['f1_score'] > float(best_result['classification_report'].split()[-2]):\n",
        "        print(\"The Deep Learning model performed better in F1-score.\")\n",
        "    elif float(best_result['classification_report'].split()[-2]) > dl_results['f1_score']:\n",
        "        print(\"The Best Classical ML model performed better in F1-score.\")\n",
        "    else:\n",
        "        print(\"Both models achieved similar F1-score.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Model Performance Comparison (Classical ML vs. Deep Learning)\n",
            "==================================================\n",
            "\n",
            "Best Classical ML Model (naive_bayes with (1, 1)-grams):\n",
            "  Accuracy: 0.9526\n",
            "  F1-score: 0.9500\n",
            "\n",
            "Deep Learning Model (MBERT):\n",
            "  Accuracy: 0.9159\n",
            "  F1-score: 0.9160\n",
            "\n",
            "--------------------------------------------------\n",
            "The Best Classical ML model performed better in Accuracy.\n",
            "The Best Classical ML model performed better in F1-score.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dee9769"
      },
      "source": [
        "## Evaluate MBERT Model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the fine-tuned MBERT model on the test set and report its accuracy, precision, recall, and F1-score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c6d68cb"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the model as requested, I will use the `trainer.predict` method to get predictions on the test set, convert logits to class labels, and then generate a detailed classification report using `sklearn.metrics.classification_report`. Finally, I will update the `dl_results` dictionary with the full report and extracted precision/recall metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "b8a1a104",
        "outputId": "2c603e66-c8bc-414f-d78e-f863211e0ce8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Use trainer.predict() on the test_dataset\n",
        "predictions_output = trainer.predict(test_dataset)\n",
        "\n",
        "# 2. Extract raw predictions (logits)\n",
        "logits = predictions_output.predictions\n",
        "\n",
        "# 3. Convert raw predictions (logits) into predicted class labels\n",
        "predicted_labels = np.argmax(logits, axis=1)\n",
        "\n",
        "# 4. Extract true labels\n",
        "true_labels = predictions_output.label_ids\n",
        "\n",
        "# 5. Generate a comprehensive classification report\n",
        "dl_classification_report = classification_report(true_labels, predicted_labels, target_names=list(label_mapping.keys()))\n",
        "\n",
        "print(\"Deep Learning Model (MBERT) Classification Report:\")\n",
        "print(dl_classification_report)\n",
        "\n",
        "# 6. Update the dl_results dictionary\n",
        "# Re-parse the report to get precision and recall for updating dl_results\n",
        "report_dict = classification_report(true_labels, predicted_labels, target_names=list(label_mapping.keys()), output_dict=True)\n",
        "\n",
        "dl_results.update({\n",
        "    'classification_report': dl_classification_report,\n",
        "    'precision_weighted': report_dict['weighted avg']['precision'],\n",
        "    'recall_weighted': report_dict['weighted avg']['recall']\n",
        "})\n",
        "\n",
        "print(\"\\nUpdated dl_results:\")\n",
        "print(dl_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Learning Model (MBERT) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.93      0.91      0.92       257\n",
            "         not       0.90      0.92      0.91       207\n",
            "\n",
            "    accuracy                           0.92       464\n",
            "   macro avg       0.91      0.92      0.92       464\n",
            "weighted avg       0.92      0.92      0.92       464\n",
            "\n",
            "\n",
            "Updated dl_results:\n",
            "{'model_type': 'MBERT', 'accuracy': 0.915948275862069, 'f1_score': 0.916036950074367, 'classification_report': '              precision    recall  f1-score   support\\n\\n        hate       0.93      0.91      0.92       257\\n         not       0.90      0.92      0.91       207\\n\\n    accuracy                           0.92       464\\n   macro avg       0.91      0.92      0.92       464\\nweighted avg       0.92      0.92      0.92       464\\n', 'precision_weighted': 0.9163395826233335, 'recall_weighted': 0.915948275862069}\n"
          ]
        }
      ]
    }
  ]
}